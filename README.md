# Amazon Sales Database API

A FastAPI-based REST API for managing Amazon product sales data from Kaggle. This project provides endpoints to query products, reviews, and users with a PostgreSQL database backend.

## Dataset Overview

This project uses the Amazon Sales DB dataset from Kaggle, which may include unrealistic values.

### Data Schema

| Field | Description |
|-------|-------------|
| `product_id` | Unique identifier for the product |
| `product_name` | Name of the product |
| `category` | Product category classification |
| `discounted_price` | Current discounted price |
| `actual_price` | Original price before discount |
| `discount_percentage` | Percentage discount applied |
| `rating` | Product rating (1-5 stars) |
| `rating_count` | Number of ratings received |
| `about_product` | Detailed product description |
| `user_id` | Unique identifier for the reviewer |
| `user_name` | Name of the reviewer |
| `review_id` | Unique identifier for the review |
| `review_title` | Short review summary |
| `review_content` | Full review text |
| `img_link` | URL to product image |
| `product_link` | Official product page URL |

## Project Structure

```
amazon-sql-api/
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ db/                      # Database configuration
â”‚   â”œâ”€â”€ docker-compose.yml   # PostgreSQL container setup
â”‚   â””â”€â”€ init/                # Database initialization scripts
â”‚       â”œâ”€â”€ 01_schema.sql    # Database schema creation
â”‚       â””â”€â”€ 02_indexes.sql   # Database indexes for performance
â”œâ”€â”€ backend/                 # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ app/                 # Main application code
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py          # FastAPI application entry point
â”‚       â”œâ”€â”€ db.py            # Database connection and session management
â”‚       â”œâ”€â”€ models.py        # SQLAlchemy ORM models
â”‚       â”œâ”€â”€ schemas.py       # Pydantic models for API serialization
â”‚       â””â”€â”€ routers/         # API route handlers
â”‚           â”œâ”€â”€ products.py   # Product-related endpoints
â”‚           â”œâ”€â”€ reviews.py   # Review-related endpoints
â”‚           â””â”€â”€ users.py     # User-related endpoints
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â””â”€â”€ load_csv.py          # CSV data import script
â””â”€â”€ data/                    # Data files
    â””â”€â”€ amazon.csv           # Raw CSV data (place your file here)
```

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.8+
- pip

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd amazon-sql-api
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

3. **Start the database**
   ```bash
   cd db
   docker-compose up -d
   ```

4. **Install Python dependencies**
   ```bash
   cd ../backend
   pip install -r requirements.txt
   ```

5. **Load the data**
   ```bash
   python scripts/load_csv.py
   ```

6. **Start the API server**
   ```bash
   python app/main.py
   ```

The API will be available at `http://localhost:8000`

## API Documentation

Once the server is running, you can access:
- **Interactive API docs**: `http://localhost:8000/docs`
- **ReDoc documentation**: `http://localhost:8000/redoc`

## Configuration

Key environment variables (see `.env.example`):
- `DATABASE_URL`: PostgreSQL connection string
- `API_HOST`: API server host (default: localhost)
- `API_PORT`: API server port (default: 8000)

## ğŸ“ License

This project uses data from Kaggle's Amazon Sales DB dataset. Please check the original dataset license for usage terms.